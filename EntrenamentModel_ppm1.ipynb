{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EntrenamentModel_ppm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWvMceL/RfX4wLtQ1zNNVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MagdaPla/UNET_PPM/blob/master/EntrenamentModel_ppm1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHTjL0yDwnsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# codi preparat només per windows\n",
        "# modificat per R-colab, \n",
        "# va a llegir els directoris a GitHub https://github.com/MagdaPla/UNET_PPM.git\n",
        "# per a poder-ho llegir bé, cada vegada monto a sample data la mateixa estructura que al github\n",
        "# canvio nom de Sample_data >>> UNET_PPM\n",
        "# i pujo les dades de nou.\n",
        "\n",
        "# aquest fitxer es va desant per defecte al meu GDrive\n",
        "# cal pujar-ho també al GitHub amb les modificacions\n",
        "\n",
        "\n",
        "# comencem a preparar la informació\n",
        "# eliminem pesos (weights) previs que hi pugui haver\n",
        "unlink(list.files(path = \"UNET_PPM/weights_r/\",full.names = TRUE))\n",
        "\n",
        "# paràmetres d'entrenament\n",
        "\n",
        "epochs = 30 #epochs = 100 \n",
        "batch_size <- 10    #batch_size <- 24\n",
        "DRAW_SAMPLES = TRUE # així copia les dades de validació d'un i altre tipus al directori corresponent\n",
        "no_cores = 6   #no_cores = 12\n",
        "lr_rate = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h72A4Bn7U7Hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "edc07fb7-000b-4add-ca6d-337399ac84c8"
      },
      "source": [
        "install.packages(\"rgdal\", dependencies=TRUE,repos='http://cran.rstudio.com/') "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Warning message in install.packages(\"rgdal\", dependencies = TRUE, repos = \"http://cran.rstudio.com/\"):\n",
            "“installation of package ‘rgdal’ had non-zero exit status”\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv3n_kr42jgS",
        "colab_type": "code",
        "outputId": "6f207d16-5ad9-47c1-8d87-7036097f4442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "# instalem els paquets necessaris\n",
        "# a Gcolab ens cal instalarlos ne nou en cada sessió\n",
        "\n",
        "install.packages(\"keras\")\n",
        "install.packages(\"tensorflow\")\n",
        "install.packages(\"reticulate\")\n",
        "install.packages(\"raster\")\n",
        "install.packages(\"abind\")\n",
        "install.packages(\"foreach\")\n",
        "install.packages(\"parallel\")\n",
        "install.packages(\"doParallel\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘rappdirs’, ‘config’, ‘reticulate’, ‘tensorflow’, ‘tfruns’, ‘zeallot’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘sp’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘iterators’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Warning message:\n",
            "“package ‘parallel’ is not available (for R version 3.6.3)”\n",
            "Warning message:\n",
            "“package ‘parallel’ is a base package, and should not be updated”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXVJhSJ2coY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9ecf2311-fd44-42cd-880f-d30527607564"
      },
      "source": [
        "library(keras)\n",
        "library(tensorflow)\n",
        "library(reticulate)\n",
        "library(raster)\n",
        "library(abind)\n",
        "library(foreach)\n",
        "library(parallel)\n",
        "library(doParallel)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading required package: sp\n",
            "\n",
            "Loading required package: iterators\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3MHq4pF7gw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set.seed(104)\n",
        "\n",
        "# per a fer reproduible les probes fixem una llavor\n",
        "# cal tenir present però que el codi que tenim es basa en un exemple basat en tensorflow v1.x\n",
        "# al collab es descarrega una versió 2\n",
        "# feun una adaptació al codi\n",
        "tf<-tf$compat.v1\n",
        "tf$set_random_seed(100)\n",
        "\n",
        "# si no funcionés, canviem el valor \"1\"\n",
        "gpu_options <- tf$GPUOptions(allow_growth=TRUE, per_process_gpu_memory_fraction = 1) #tf$GPUOptions(per_process_gpu_memory_fraction = 0.3)\n",
        "config <- tf$ConfigProto(gpu_options = gpu_options)\n",
        "\n",
        "session_conf <- config\n",
        "sess <- tf$Session(graph = tf$get_default_graph(), config = session_conf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h65SxFmB8Fi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paràmetres -----------------------------------------------------\n",
        "\n",
        "# directoris de les imatges i màscares preparades per l'entrenament/validació\n",
        "images_dir <- \"UNET_PPM/rgb/\" \n",
        "masks_dir <- \"UNET_PPM/masc/\"\n",
        "\n",
        "# \n",
        "if (DRAW_SAMPLES) {\n",
        "  \n",
        "  unlink(list.files(path = \"UNET_PPM/valid_masc/\",full.names = TRUE))\n",
        "  unlink(list.files(path = \"UNET_PPM/valid_rgb/\",full.names = TRUE))\n",
        "  \n",
        "  # nombre d'imatges per l'entrenament (80%)\n",
        "  train_samples <- length(list.files(images_dir)) #144\n",
        "  train_index <- sample(1:train_samples, round(train_samples * 0.8))\n",
        "  val_index <- c(1:train_samples)[-train_index]\n",
        "  \n",
        "  \n",
        "  # desar les imatges de validació a:\n",
        "  valid_save=list.files(images_dir,full.names = TRUE)\n",
        "  valid_save=valid_save[val_index]\n",
        "  file.copy(from=valid_save,to=\"UNET_PPM/valid_rgb/\")\n",
        "  \n",
        "  valid_save=list.files(masks_dir,full.names = TRUE)\n",
        "  valid_save=valid_save[val_index]\n",
        "  file.copy(from=valid_save,to=\"UNET_PPM/valid_masc/\")\n",
        "  \n",
        "  save(train_index, val_index, file = \"UNET_PPM/train_val_indices.RData\")\n",
        "  \n",
        "} else {\n",
        "  load(\"UNET_PPM/train_val_indices.RData\", verbose=T)\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcPoh92I8qTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funció \"Loss\"  -----------------------------------------------------\n",
        "\n",
        "# hem d'adaptar la manera de fer el set_session de keras v2 a v1\n",
        "K<-tf$compat.v1.keras.backend\n",
        "K$set_session(sess)\n",
        "\n",
        "dice_coef <- custom_metric(\"custom\", function(y_true, y_pred, smooth = 1.0) {\n",
        "  y_true_f <- k_flatten(y_true)\n",
        "  y_pred_f <- k_flatten(y_pred)\n",
        "  intersection <- k_sum(y_true_f * y_pred_f)\n",
        "  result <- (2 * intersection + smooth) / \n",
        "    (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n",
        "  return(result)\n",
        "})\n",
        "\n",
        "bce_dice_loss <- function(y_true, y_pred) {\n",
        "  result <- loss_binary_crossentropy(y_true, y_pred) +\n",
        "    (1 - dice_coef(y_true, y_pred))\n",
        "  return(result)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcN6dhhdADb5",
        "colab_type": "code",
        "outputId": "fdb0b08f-3bae-42ab-eb80-c5940385d5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# U-net 128 -----------------------------------------------------\n",
        "\n",
        "get_unet_128 <- function(input_shape = c(128, 128, 3),\n",
        "                         num_classes = 1) {\n",
        "  \n",
        "  inputs <- layer_input(shape = input_shape)\n",
        "  # 128\n",
        "  \n",
        "  down1 <- inputs %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down1_pool <- down1 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 64\n",
        "  \n",
        "  down2 <- down1_pool %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down2_pool <- down2 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 32\n",
        "  \n",
        "  down3 <- down2_pool %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down3_pool <- down3 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 16\n",
        "  \n",
        "  down4 <- down3_pool %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down4_pool <- down4 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 8\n",
        "  \n",
        "  center <- down4_pool %>%\n",
        "    layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  # center\n",
        "  \n",
        "  up4 <- center %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down4, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 16\n",
        "  \n",
        "  up3 <- up4 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down3, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 32\n",
        "  \n",
        "  up2 <- up3 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down2, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 64\n",
        "  \n",
        "  up1 <- up2 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down1, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 128\n",
        "  \n",
        "  classify <- layer_conv_2d(up1,\n",
        "                            filters = num_classes, \n",
        "                            kernel_size = c(1, 1),\n",
        "                            activation = \"sigmoid\")\n",
        "  \n",
        "  \n",
        "  model <- keras_model(\n",
        "    inputs = inputs,\n",
        "    outputs = classify\n",
        "  )\n",
        "  \n",
        "  model %>% compile(\n",
        "    optimizer = optimizer_rmsprop(lr = 0.0001),\n",
        "    loss = bce_dice_loss,\n",
        "    metrics = c(dice_coef)\n",
        "  )\n",
        "  \n",
        "  return(model)\n",
        "}\n",
        "\n",
        "model <- get_unet_128()\n",
        "model\n",
        "\n",
        "# per utilitzar \"pesos\" d'entrenaments previes utilitzar la funció: \"load_model_weights_hdf5\"\n",
        "# per exemple:\n",
        "# load_model_weights_hdf5(model, \"./weights_r_save/unet64_178.h5\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model\n",
              "Model: \"model\"\n",
              "________________________________________________________________________________\n",
              "Layer (type)              Output Shape      Param #  Connected to               \n",
              "================================================================================\n",
              "input_1 (InputLayer)      [(None, 128, 128, 0                                   \n",
              "________________________________________________________________________________\n",
              "conv2d (Conv2D)           (None, 128, 128,  1792     input_1[0][0]              \n",
              "________________________________________________________________________________\n",
              "batch_normalization (Batc (None, 128, 128,  256      conv2d[0][0]               \n",
              "________________________________________________________________________________\n",
              "activation (Activation)   (None, 128, 128,  0        batch_normalization[0][0]  \n",
              "________________________________________________________________________________\n",
              "conv2d_1 (Conv2D)         (None, 128, 128,  36928    activation[0][0]           \n",
              "________________________________________________________________________________\n",
              "batch_normalization_1 (Ba (None, 128, 128,  256      conv2d_1[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_1 (Activation) (None, 128, 128,  0        batch_normalization_1[0][0]\n",
              "________________________________________________________________________________\n",
              "max_pooling2d (MaxPooling (None, 64, 64, 64 0        activation_1[0][0]         \n",
              "________________________________________________________________________________\n",
              "conv2d_2 (Conv2D)         (None, 64, 64, 12 73856    max_pooling2d[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_2 (Ba (None, 64, 64, 12 512      conv2d_2[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_2 (Activation) (None, 64, 64, 12 0        batch_normalization_2[0][0]\n",
              "________________________________________________________________________________\n",
              "conv2d_3 (Conv2D)         (None, 64, 64, 12 147584   activation_2[0][0]         \n",
              "________________________________________________________________________________\n",
              "batch_normalization_3 (Ba (None, 64, 64, 12 512      conv2d_3[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_3 (Activation) (None, 64, 64, 12 0        batch_normalization_3[0][0]\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_1 (MaxPooli (None, 32, 32, 12 0        activation_3[0][0]         \n",
              "________________________________________________________________________________\n",
              "conv2d_4 (Conv2D)         (None, 32, 32, 25 295168   max_pooling2d_1[0][0]      \n",
              "________________________________________________________________________________\n",
              "batch_normalization_4 (Ba (None, 32, 32, 25 1024     conv2d_4[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_4 (Activation) (None, 32, 32, 25 0        batch_normalization_4[0][0]\n",
              "________________________________________________________________________________\n",
              "conv2d_5 (Conv2D)         (None, 32, 32, 25 590080   activation_4[0][0]         \n",
              "________________________________________________________________________________\n",
              "batch_normalization_5 (Ba (None, 32, 32, 25 1024     conv2d_5[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_5 (Activation) (None, 32, 32, 25 0        batch_normalization_5[0][0]\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_2 (MaxPooli (None, 16, 16, 25 0        activation_5[0][0]         \n",
              "________________________________________________________________________________\n",
              "conv2d_6 (Conv2D)         (None, 16, 16, 51 1180160  max_pooling2d_2[0][0]      \n",
              "________________________________________________________________________________\n",
              "batch_normalization_6 (Ba (None, 16, 16, 51 2048     conv2d_6[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_6 (Activation) (None, 16, 16, 51 0        batch_normalization_6[0][0]\n",
              "________________________________________________________________________________\n",
              "conv2d_7 (Conv2D)         (None, 16, 16, 51 2359808  activation_6[0][0]         \n",
              "________________________________________________________________________________\n",
              "batch_normalization_7 (Ba (None, 16, 16, 51 2048     conv2d_7[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_7 (Activation) (None, 16, 16, 51 0        batch_normalization_7[0][0]\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_3 (MaxPooli (None, 8, 8, 512) 0        activation_7[0][0]         \n",
              "________________________________________________________________________________\n",
              "conv2d_8 (Conv2D)         (None, 8, 8, 1024 4719616  max_pooling2d_3[0][0]      \n",
              "________________________________________________________________________________\n",
              "batch_normalization_8 (Ba (None, 8, 8, 1024 4096     conv2d_8[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_8 (Activation) (None, 8, 8, 1024 0        batch_normalization_8[0][0]\n",
              "________________________________________________________________________________\n",
              "conv2d_9 (Conv2D)         (None, 8, 8, 1024 9438208  activation_8[0][0]         \n",
              "________________________________________________________________________________\n",
              "batch_normalization_9 (Ba (None, 8, 8, 1024 4096     conv2d_9[0][0]             \n",
              "________________________________________________________________________________\n",
              "activation_9 (Activation) (None, 8, 8, 1024 0        batch_normalization_9[0][0]\n",
              "________________________________________________________________________________\n",
              "up_sampling2d (UpSampling (None, 16, 16, 10 0        activation_9[0][0]         \n",
              "________________________________________________________________________________\n",
              "concatenate (Concatenate) (None, 16, 16, 15 0        activation_7[0][0]         \n",
              "                                                     up_sampling2d[0][0]        \n",
              "________________________________________________________________________________\n",
              "conv2d_10 (Conv2D)        (None, 16, 16, 51 7078400  concatenate[0][0]          \n",
              "________________________________________________________________________________\n",
              "batch_normalization_10 (B (None, 16, 16, 51 2048     conv2d_10[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_10 (Activation (None, 16, 16, 51 0        batch_normalization_10[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_11 (Conv2D)        (None, 16, 16, 51 2359808  activation_10[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_11 (B (None, 16, 16, 51 2048     conv2d_11[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_11 (Activation (None, 16, 16, 51 0        batch_normalization_11[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_12 (Conv2D)        (None, 16, 16, 51 2359808  activation_11[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_12 (B (None, 16, 16, 51 2048     conv2d_12[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_12 (Activation (None, 16, 16, 51 0        batch_normalization_12[0][0\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_1 (UpSampli (None, 32, 32, 51 0        activation_12[0][0]        \n",
              "________________________________________________________________________________\n",
              "concatenate_1 (Concatenat (None, 32, 32, 76 0        activation_5[0][0]         \n",
              "                                                     up_sampling2d_1[0][0]      \n",
              "________________________________________________________________________________\n",
              "conv2d_13 (Conv2D)        (None, 32, 32, 25 1769728  concatenate_1[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_13 (B (None, 32, 32, 25 1024     conv2d_13[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_13 (Activation (None, 32, 32, 25 0        batch_normalization_13[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_14 (Conv2D)        (None, 32, 32, 25 590080   activation_13[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_14 (B (None, 32, 32, 25 1024     conv2d_14[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_14 (Activation (None, 32, 32, 25 0        batch_normalization_14[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_15 (Conv2D)        (None, 32, 32, 25 590080   activation_14[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_15 (B (None, 32, 32, 25 1024     conv2d_15[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_15 (Activation (None, 32, 32, 25 0        batch_normalization_15[0][0\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_2 (UpSampli (None, 64, 64, 25 0        activation_15[0][0]        \n",
              "________________________________________________________________________________\n",
              "concatenate_2 (Concatenat (None, 64, 64, 38 0        activation_3[0][0]         \n",
              "                                                     up_sampling2d_2[0][0]      \n",
              "________________________________________________________________________________\n",
              "conv2d_16 (Conv2D)        (None, 64, 64, 12 442496   concatenate_2[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_16 (B (None, 64, 64, 12 512      conv2d_16[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_16 (Activation (None, 64, 64, 12 0        batch_normalization_16[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_17 (Conv2D)        (None, 64, 64, 12 147584   activation_16[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_17 (B (None, 64, 64, 12 512      conv2d_17[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_17 (Activation (None, 64, 64, 12 0        batch_normalization_17[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_18 (Conv2D)        (None, 64, 64, 12 147584   activation_17[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_18 (B (None, 64, 64, 12 512      conv2d_18[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_18 (Activation (None, 64, 64, 12 0        batch_normalization_18[0][0\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_3 (UpSampli (None, 128, 128,  0        activation_18[0][0]        \n",
              "________________________________________________________________________________\n",
              "concatenate_3 (Concatenat (None, 128, 128,  0        activation_1[0][0]         \n",
              "                                                     up_sampling2d_3[0][0]      \n",
              "________________________________________________________________________________\n",
              "conv2d_19 (Conv2D)        (None, 128, 128,  110656   concatenate_3[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_19 (B (None, 128, 128,  256      conv2d_19[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_19 (Activation (None, 128, 128,  0        batch_normalization_19[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_20 (Conv2D)        (None, 128, 128,  36928    activation_19[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_20 (B (None, 128, 128,  256      conv2d_20[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_20 (Activation (None, 128, 128,  0        batch_normalization_20[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_21 (Conv2D)        (None, 128, 128,  36928    activation_20[0][0]        \n",
              "________________________________________________________________________________\n",
              "batch_normalization_21 (B (None, 128, 128,  256      conv2d_21[0][0]            \n",
              "________________________________________________________________________________\n",
              "activation_21 (Activation (None, 128, 128,  0        batch_normalization_21[0][0\n",
              "________________________________________________________________________________\n",
              "conv2d_22 (Conv2D)        (None, 128, 128,  65       activation_21[0][0]        \n",
              "================================================================================\n",
              "Total params: 34,540,737\n",
              "Trainable params: 34,527,041\n",
              "Non-trainable params: 13,696\n",
              "________________________________________________________________________________\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzOkOrzKAbZO",
        "colab_type": "code",
        "outputId": "98e95fb0-0599-42ec-be71-2efa6efaea99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "## definim el nombre de clusters\n",
        "cl <- makePSOCKcluster(no_cores) \n",
        "\n",
        "clusterEvalQ(cl, {\n",
        "  \n",
        "  library(abind)     \n",
        "  library(raster)\n",
        "  library(reticulate)\n",
        "  \n",
        "  # Llegim funcions d'augment -----------------------------------------------------\n",
        "  \n",
        "  imagesRead <- function(image_file,mask_file)\n",
        "  {\n",
        "    \n",
        "    img <- brick(image_file)\n",
        "    mask <- raster(mask_file)\n",
        "    \n",
        "    return(list(img = img, mask = mask))\n",
        "  }\n",
        "  \n",
        "  # randomHorizontalFlip : rotacions i inversions + rotacions\n",
        "  randomHorizontalFlip <- function(img,mask,u = 0) {\n",
        "    if (rnorm(1) < u) return(list(img = img, mask = mask))\n",
        "    r_angle=sample(c(2,3,4,5,6,7,8),1)\n",
        "    if(r_angle==2) {return(list(img = flip(t(img),direction = 1), mask = flip(t(mask),direction = 1)))}\n",
        "    if(r_angle==3) {return(list(img = flip(t(flip(t(img),direction = 1)),direction = 1), mask = flip(t(flip(t(mask),direction = 1)),direction = 1)))}\n",
        "    if(r_angle==4) {return(list(img = flip(t(img),direction = 2), mask = flip(t(mask),direction = 2)))}\n",
        "    if(r_angle==5) {return(list(img = flip(img,direction = 1), mask = flip(mask,direction = 1)))}\n",
        "    if(r_angle==6) {return(list(img = flip(t(flip(img,direction = 1)),direction = 1), mask = flip(t(flip(mask,direction = 1)),direction = 1)))}\n",
        "    if(r_angle==7) {return(list(img = flip(t(flip(t(flip(img,direction = 1)),direction = 1)),direction = 1), mask = flip(t(flip(t(flip(mask,direction = 1)),direction = 1)),direction = 1)))}\n",
        "    if(r_angle==8) {return(list(img = flip(t(flip(img,direction = 1)),direction = 2), mask = flip(t(flip(mask,direction = 1)),direction = 2)))}\n",
        "  }\n",
        "  \n",
        "  # add a shift to the bands\n",
        "  randomVariability = function(img, u = 0, variability = c(90, 110)) {\n",
        "    if (rnorm(1) < u) return(img)\n",
        "    variability_shift = runif(1, variability[1], variability[2])/100\n",
        "    img = img * variability_shift\n",
        "    return(img)\n",
        "  }\n",
        "  \n",
        "  \n",
        "  img2arr <- function(image) {\n",
        "    image <- as.array(image)\n",
        "    result <- aperm(image, c(2,1,3))\n",
        "    result <- result/255 # to have values between 0 and 1\n",
        "    array_reshape(result,  c(1, dim(image)[1], dim(image)[2], dim(image)[3]))\n",
        "  }\n",
        "  \n",
        "  \n",
        "  mask2arr <- function(mask) {\n",
        "    mask=as.array(mask[[1]])\n",
        "    result <- aperm(mask, c(2,1,3))\n",
        "    result=result[,,1]\n",
        "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
        "  }\n",
        "  \n",
        "})\n",
        "\n",
        "\n",
        "registerDoParallel(cl)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[[1]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[2]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[3]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[4]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[5]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[6]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n"
            ],
            "text/latex": "\\begin{enumerate}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\end{enumerate}\n",
            "text/markdown": "1. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n2. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n3. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n4. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n5. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n6. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n\n\n",
            "text/html": [
              "<ol>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ZGInTRBH46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator <- function(images_dir, \n",
        "                            samples_index,\n",
        "                            masks_dir, \n",
        "                            batch_size) {\n",
        "  images_iter <- list.files(images_dir, \n",
        "                            pattern = \".tif\", \n",
        "                            full.names = TRUE)[samples_index] # for current epoch\n",
        "  images_all <- list.files(images_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index]  # for next epoch\n",
        "  masks_iter <- list.files(masks_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index] # for current epoch\n",
        "  masks_all <- list.files(masks_dir, \n",
        "                          pattern = \".tif\",\n",
        "                          full.names = TRUE)[samples_index] # for next epoch\n",
        "  \n",
        "  function() {\n",
        "    \n",
        "    # start new epoch\n",
        "    if (length(images_iter) < batch_size) {\n",
        "      images_iter <<- images_all\n",
        "      masks_iter <<- masks_all\n",
        "    }\n",
        "    \n",
        "    batch_ind <- sample(1:length(images_iter), batch_size)\n",
        "    \n",
        "    batch_images_list <- images_iter[batch_ind]\n",
        "    images_iter <<- images_iter[-batch_ind]\n",
        "    batch_masks_list <- masks_iter[batch_ind]\n",
        "    masks_iter <<- masks_iter[-batch_ind]\n",
        "    \n",
        "    \n",
        "    x_y_batch <- foreach(i = 1:batch_size) %dopar% {\n",
        "      x_y_imgs <- imagesRead(image_file = batch_images_list[i],\n",
        "                             mask_file = batch_masks_list[i])\n",
        "      \n",
        "      # flip all side and invert\n",
        "      x_y_imgs <- randomHorizontalFlip(x_y_imgs$img,x_y_imgs$mask)\n",
        "      \n",
        "      # add some variability to the values\n",
        "      x_y_imgs$img = randomVariability(x_y_imgs$img, u = 0, variability = c(90, 110))\n",
        "      \n",
        "      # return as arrays\n",
        "      x_y_arr <- list(x = img2arr(x_y_imgs$img),\n",
        "                      y = mask2arr(x_y_imgs$mask))\n",
        "    }\n",
        "    \n",
        "    x_y_batch <- purrr::transpose(x_y_batch)\n",
        "    \n",
        "    x_batch <- do.call(abind, c(x_y_batch$x, list(along = 1)))\n",
        "    \n",
        "    y_batch <- do.call(abind, c(x_y_batch$y, list(along = 1)))\n",
        "    \n",
        "    result <- list(keras_array(x_batch), keras_array(y_batch))\n",
        "    return(result)\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWgIVMo3BRlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_generator <- function(images_dir, \n",
        "                          samples_index,\n",
        "                          masks_dir, \n",
        "                          batch_size) {\n",
        "  images_iter <- list.files(images_dir, \n",
        "                            pattern = \".tif\", \n",
        "                            full.names = TRUE)[samples_index] # for current epoch\n",
        "  images_all <- list.files(images_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index]  # for next epoch\n",
        "  masks_iter <- list.files(masks_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index] # for current epoch\n",
        "  masks_all <- list.files(masks_dir, \n",
        "                          pattern = \".tif\",\n",
        "                          full.names = TRUE)[samples_index] # for next epoch\n",
        "  \n",
        "  function() {\n",
        "    \n",
        "    # start new epoch\n",
        "    if (length(images_iter) < batch_size) {\n",
        "      images_iter <<- images_all\n",
        "      masks_iter <<- masks_all\n",
        "    }\n",
        "    \n",
        "    batch_ind <- sample(1:length(images_iter), batch_size)\n",
        "    \n",
        "    batch_images_list <- images_iter[batch_ind]\n",
        "    images_iter <<- images_iter[-batch_ind]\n",
        "    batch_masks_list <- masks_iter[batch_ind]\n",
        "    masks_iter <<- masks_iter[-batch_ind]\n",
        "    \n",
        "    \n",
        "    x_y_batch <- foreach(i = 1:batch_size) %dopar% {\n",
        "      x_y_imgs <- imagesRead(image_file = batch_images_list[i],\n",
        "                             mask_file = batch_masks_list[i])\n",
        "      # without augmentation\n",
        "      ########################################\n",
        "      ########################################\n",
        "      # return as arrays\n",
        "      x_y_arr <- list(x = img2arr(x_y_imgs$img),\n",
        "                      y = mask2arr(x_y_imgs$mask))\n",
        "    }\n",
        "    \n",
        "    x_y_batch <- purrr::transpose(x_y_batch)\n",
        "    \n",
        "    x_batch <- do.call(abind, c(x_y_batch$x, list(along = 1)))\n",
        "    \n",
        "    y_batch <- do.call(abind, c(x_y_batch$y, list(along = 1)))\n",
        "    \n",
        "    result <- list(keras_array(x_batch), keras_array(y_batch))\n",
        "    return(result)\n",
        "  }\n",
        "}\n",
        "\n",
        "train_iterator <- py_iterator(train_generator(images_dir = images_dir,\n",
        "                                              masks_dir = masks_dir,\n",
        "                                              samples_index = train_index,\n",
        "                                              batch_size = batch_size))\n",
        "\n",
        "val_iterator <- py_iterator(val_generator(images_dir = images_dir,\n",
        "                                          masks_dir = masks_dir,\n",
        "                                          samples_index = val_index,\n",
        "                                          batch_size = batch_size))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm6ShPVWBbcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entrenament -----------------------------------------------------\n",
        "\n",
        "# callbacks\n",
        "callbacks_list <- list(\n",
        "  callback_model_checkpoint(filepath = \"UNET_PPM/weights_r/unet64_{epoch:03d}.h5\",\n",
        "                            monitor = \"val_custom\",\n",
        "                            save_best_only = FALSE,\n",
        "                            save_weights_only = TRUE,\n",
        "                            mode = \"max\" ,save_freq = TRUE)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9pYk1onBuGY",
        "colab_type": "code",
        "outputId": "476b8659-ee50-403c-eb66-517e4bfa05bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model %>% fit_generator(\n",
        "  generator=train_iterator,\n",
        "  steps_per_epoch = as.integer(length(train_index) / batch_size),\n",
        "  epochs = epochs,\n",
        "  validation_data = val_iterator,\n",
        "  validation_steps = as.integer(length(val_index) / batch_size),\n",
        "  verbose = 1,  callbacks = callbacks_list\n",
        ")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error occurred in generator: task 1 failed - \"Cannot create RasterLayer object from this file; perhaps you need to install rgdal first\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in py_call_impl(callable, dots$args, dots$keywords): StopIteration: \n\nDetailed traceback: \n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1479, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\n    return method(self, *args, **kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 815, in fit\n    model=self)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1112, in __init__\n    model=model)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 772, in __init__\n    peek, x = self._peek_and_restore(x)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 830, in _peek_and_restore\n    peek = next(x)\n  File \"/usr/local/lib/R/site-library/reticulate/python/rpytools/generator.py\", line 23, in __next__\n    return self.next()\n  File \"/usr/local/lib/R/site-library/reticulate/python/rpytools/generator.py\", line 40, in next\n    raise StopIteration()\n\nTraceback:\n",
            "1. model %>% fit_generator(generator = train_iterator, steps_per_epoch = as.integer(length(train_index)/batch_size), \n .     epochs = epochs, validation_data = val_iterator, validation_steps = as.integer(length(val_index)/batch_size), \n .     verbose = 1, callbacks = callbacks_list)",
            "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
            "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
            "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
            "5. `_fseq`(`_lhs`)",
            "6. freduce(value, `_function_list`)",
            "7. withVisible(function_list[[k]](value))",
            "8. function_list[[k]](value)",
            "9. fit_generator(., generator = train_iterator, steps_per_epoch = as.integer(length(train_index)/batch_size), \n .     epochs = epochs, validation_data = val_iterator, validation_steps = as.integer(length(val_index)/batch_size), \n .     verbose = 1, callbacks = callbacks_list)",
            "10. call_generator_function(object$fit_generator, list(generator = generator, \n  .     steps_per_epoch = as.integer(steps_per_epoch), epochs = as.integer(epochs), \n  .     verbose = as.integer(verbose), callbacks = normalize_callbacks_with_metrics(view_metrics, \n  .         callbacks), validation_data = validation_data, validation_steps = as_nullable_integer(validation_steps), \n  .     class_weight = as_class_weight(class_weight), max_queue_size = as.integer(max_queue_size), \n  .     workers = as.integer(workers), initial_epoch = as.integer(initial_epoch)))",
            "11. do.call(func, args)",
            "12. (structure(function (...) \n  . {\n  .     dots <- py_resolve_dots(list(...))\n  .     result <- py_call_impl(callable, dots$args, dots$keywords)\n  .     if (convert) \n  .         result <- py_to_r(result)\n  .     if (is.null(result)) \n  .         invisible(result)\n  .     else result\n  . }, class = c(\"python.builtin.method\", \"python.builtin.object\"\n  . ), py_object = <environment>))(generator = <environment>, steps_per_epoch = 11L, \n  .     epochs = 30L, verbose = 1L, callbacks = list(<environment>, \n  .         <environment>), validation_data = <environment>, validation_steps = 2L, \n  .     class_weight = NULL, max_queue_size = 10L, workers = 1L, \n  .     initial_epoch = 0L, use_multiprocessing = FALSE)",
            "13. py_call_impl(callable, dots$args, dots$keywords)"
          ]
        }
      ]
    }
  ]
}