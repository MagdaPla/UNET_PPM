{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOwiMbbaCEkgxvs4FF2kvu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MagdaPla/UNET_PPM/blob/master/EntrenamentModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsT_8PB7X6aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code runs only on Windows because of specific parallel backend. \n",
        "# set working directory\n",
        "# setwd('C:/Taller/UOC/Aules/TFM/Exemples/UNET_PPM')\n",
        "\n",
        "# remove previous trained weights if any\n",
        "unlink(list.files(path = \"./weights_r/\",full.names = TRUE))\n",
        "\n",
        "# training parameters\n",
        "epochs = 30\n",
        "batch_size <- 24\n",
        "DRAW_SAMPLES = TRUE \n",
        "no_cores = 12\n",
        "lr_rate = 0.0001\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6EequpudpEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "library(keras)\n",
        "library(tensorflow)\n",
        "library(reticulate)\n",
        "library(raster)\n",
        "library(abind)\n",
        "library(foreach)\n",
        "library(parallel)\n",
        "library(doParallel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG0Hs0VTCZSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set.seed(104)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTip3TdH_z3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for reproducibility\n",
        "tf$random.set_seed(100) \n",
        "# no em funciona aquest comandament, sembla que la versiÃ³ de tensorflow 2.0 no admet i no trobo com actualitzar el codi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiSWTh3GA_yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if it doesnt work change the 1 value\n",
        "# not applied in Colab\n",
        "gpu_options <- tf$GPUOptions(allow_growth=TRUE, per_process_gpu_memory_fraction = 0.3) #tf$GPUOptions(per_process_gpu_memory_fraction = 0.3)\n",
        "config <- tf$ConfigProto(gpu_options = gpu_options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge9bMMyuWYMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not applied in Colab\n",
        "session_conf <- config\n",
        "sess <- tf$Session(graph = tf$get_default_graph(), config = session_conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk29SZTEWw66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters -----------------------------------------------------\n",
        "\n",
        "# directory of the image and object masks\n",
        "images_dir <- \"./rgb/\" \n",
        "masks_dir <- \"./masc/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlj9BbT7W_fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "if (DRAW_SAMPLES) {\n",
        "  \n",
        "  unlink(list.files(path = \"./valid_masc/\",full.names = TRUE))\n",
        "  unlink(list.files(path = \"./valid_rgb/\",full.names = TRUE))\n",
        "  \n",
        "  # number of image for training\n",
        "  train_samples <- length(list.files(images_dir)) # 669\n",
        "  train_index <- sample(1:train_samples, round(train_samples * 0.8)) # 80%\n",
        "  val_index <- c(1:train_samples)[-train_index]\n",
        "  \n",
        "  \n",
        "  # sauver les images de validation dans\n",
        "  valid_save=list.files(images_dir,full.names = TRUE)\n",
        "  valid_save=valid_save[val_index]\n",
        "  file.copy(from=valid_save,to=\"./valid_rgb/\")\n",
        "  \n",
        "  valid_save=list.files(masks_dir,full.names = TRUE)\n",
        "  valid_save=valid_save[val_index]\n",
        "  file.copy(from=valid_save,to=\"./valid_masc/\")\n",
        "  \n",
        "  save(train_index, val_index, file = \"./train_val_indices.RData\")\n",
        "  \n",
        "} else {\n",
        "  load(\"./train_val_indices.RData\", verbose=T)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHhqe1UCXFzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss function -----------------------------------------------------\n",
        "\n",
        "dice_coef <- custom_metric(\"custom\", function(y_true, y_pred, smooth = 1.0) {\n",
        "  y_true_f <- k_flatten(y_true)\n",
        "  y_pred_f <- k_flatten(y_pred)\n",
        "  intersection <- k_sum(y_true_f * y_pred_f)\n",
        "  result <- (2 * intersection + smooth) / \n",
        "    (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n",
        "  return(result)\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkAtM0brXXIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bce_dice_loss <- function(y_true, y_pred) {\n",
        "  result <- loss_binary_crossentropy(y_true, y_pred) +\n",
        "    (1 - dice_coef(y_true, y_pred))\n",
        "  return(result)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCeLUS_TXajr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_unet_128 <- function(input_shape = c(128, 128, 3),\n",
        "                         num_classes = 1) {\n",
        "  \n",
        "  inputs <- layer_input(shape = input_shape)\n",
        "  # 128\n",
        "  \n",
        "  down1 <- inputs %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down1_pool <- down1 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 64\n",
        "  \n",
        "  down2 <- down1_pool %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down2_pool <- down2 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 32\n",
        "  \n",
        "  down3 <- down2_pool %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down3_pool <- down3 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 16\n",
        "  \n",
        "  down4 <- down3_pool %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down4_pool <- down4 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 8\n",
        "  \n",
        "  center <- down4_pool %>%\n",
        "    layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  # center\n",
        "  \n",
        "  up4 <- center %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down4, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 16\n",
        "  \n",
        "  up3 <- up4 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down3, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 32\n",
        "  \n",
        "  up2 <- up3 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down2, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 64\n",
        "  \n",
        "  up1 <- up2 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down1, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 128\n",
        "  \n",
        "  classify <- layer_conv_2d(up1,\n",
        "                            filters = num_classes, \n",
        "                            kernel_size = c(1, 1),\n",
        "                            activation = \"sigmoid\")\n",
        "  \n",
        "  \n",
        "  model <- keras_model(\n",
        "    inputs = inputs,\n",
        "    outputs = classify\n",
        "  )\n",
        "  return(model)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcIIrtQiYQbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model <- get_unet_128()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMmc8GjoY1H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cl <- makePSOCKcluster(no_cores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I7MqQPjZDCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## define number of clusters\n",
        "cl <- makePSOCKcluster(no_cores) \n",
        "\n",
        "clusterEvalQ(cl, {\n",
        "  \n",
        "  library(abind)     \n",
        "  library(raster)\n",
        "  library(reticulate)\n",
        "  \n",
        "  # Read and augmentation functions -----------------------------------------------------\n",
        "  \n",
        "  imagesRead <- function(image_file,mask_file)\n",
        "  {\n",
        "    \n",
        "    img <- brick(image_file)\n",
        "    mask <- raster(mask_file)\n",
        "    \n",
        "    return(list(img = img, mask = mask))\n",
        "  }\n",
        "  \n",
        "  # randomHorizontalFlip rotations and inversion + rotations\n",
        "  randomHorizontalFlip <- function(img,mask,u = 0) {\n",
        "    if (rnorm(1) < u) return(list(img = img, mask = mask))\n",
        "    r_angle=sample(c(2,3,4,5,6,7,8),1)\n",
        "    if(r_angle==2) {return(list(img = flip(t(img),direction = 1), mask = flip(t(mask),direction = 1)))}\n",
        "    if(r_angle==3) {return(list(img = flip(t(flip(t(img),direction = 1)),direction = 1), mask = flip(t(flip(t(mask),direction = 1)),direction = 1)))}\n",
        "    if(r_angle==4) {return(list(img = flip(t(img),direction = 2), mask = flip(t(mask),direction = 2)))}\n",
        "    if(r_angle==5) {return(list(img = flip(img,direction = 1), mask = flip(mask,direction = 1)))}\n",
        "    if(r_angle==6) {return(list(img = flip(t(flip(img,direction = 1)),direction = 1), mask = flip(t(flip(mask,direction = 1)),direction = 1)))}\n",
        "    if(r_angle==7) {return(list(img = flip(t(flip(t(flip(img,direction = 1)),direction = 1)),direction = 1), mask = flip(t(flip(t(flip(mask,direction = 1)),direction = 1)),direction = 1)))}\n",
        "    if(r_angle==8) {return(list(img = flip(t(flip(img,direction = 1)),direction = 2), mask = flip(t(flip(mask,direction = 1)),direction = 2)))}\n",
        "  }\n",
        "  \n",
        "  # add a shift to the bands\n",
        "  randomVariability = function(img, u = 0, variability = c(90, 110)) {\n",
        "    if (rnorm(1) < u) return(img)\n",
        "    variability_shift = runif(1, variability[1], variability[2])/100\n",
        "    img = img * variability_shift\n",
        "    return(img)\n",
        "  }\n",
        "  \n",
        "  \n",
        "  img2arr <- function(image) {\n",
        "    image <- as.array(image)\n",
        "    result <- aperm(image, c(2,1,3))\n",
        "    result <- result/255 # to have values between 0 and 1\n",
        "    array_reshape(result,  c(1, dim(image)[1], dim(image)[2], dim(image)[3]))\n",
        "  }\n",
        "  \n",
        "  \n",
        "  mask2arr <- function(mask) {\n",
        "    mask=as.array(mask[[1]])\n",
        "    result <- aperm(mask, c(2,1,3))\n",
        "    result=result[,,1]\n",
        "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
        "  }\n",
        "  \n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYydraBvZfl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator <- function(images_dir, \n",
        "                            samples_index,\n",
        "                            masks_dir, \n",
        "                            batch_size) {\n",
        "  images_iter <- list.files(images_dir, \n",
        "                            pattern = \".tif\", \n",
        "                            full.names = TRUE)[samples_index] # for current epoch\n",
        "  images_all <- list.files(images_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index]  # for next epoch\n",
        "  masks_iter <- list.files(masks_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index] # for current epoch\n",
        "  masks_all <- list.files(masks_dir, \n",
        "                          pattern = \".tif\",\n",
        "                          full.names = TRUE)[samples_index] # for next epoch\n",
        "  \n",
        "  function() {\n",
        "    \n",
        "    # start new epoch\n",
        "    if (length(images_iter) < batch_size) {\n",
        "      images_iter <<- images_all\n",
        "      masks_iter <<- masks_all\n",
        "    }\n",
        "    \n",
        "    batch_ind <- sample(1:length(images_iter), batch_size)\n",
        "    \n",
        "    batch_images_list <- images_iter[batch_ind]\n",
        "    images_iter <<- images_iter[-batch_ind]\n",
        "    batch_masks_list <- masks_iter[batch_ind]\n",
        "    masks_iter <<- masks_iter[-batch_ind]\n",
        "    \n",
        "    \n",
        "    x_y_batch <- foreach(i = 1:batch_size) %dopar% {\n",
        "      x_y_imgs <- imagesRead(image_file = batch_images_list[i],\n",
        "                             mask_file = batch_masks_list[i])\n",
        "      \n",
        "      # flip all side and invert\n",
        "      x_y_imgs <- randomHorizontalFlip(x_y_imgs$img,x_y_imgs$mask)\n",
        "      \n",
        "      # add some variability to the values\n",
        "      x_y_imgs$img = randomVariability(x_y_imgs$img, u = 0, variability = c(90, 110))\n",
        "      \n",
        "      # return as arrays\n",
        "      x_y_arr <- list(x = img2arr(x_y_imgs$img),\n",
        "                      y = mask2arr(x_y_imgs$mask))\n",
        "    }\n",
        "    \n",
        "    x_y_batch <- purrr::transpose(x_y_batch)\n",
        "    \n",
        "    x_batch <- do.call(abind, c(x_y_batch$x, list(along = 1)))\n",
        "    \n",
        "    y_batch <- do.call(abind, c(x_y_batch$y, list(along = 1)))\n",
        "    \n",
        "    result <- list(keras_array(x_batch), keras_array(y_batch))\n",
        "    return(result)\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOnpLlREZo1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_generator <- function(images_dir, \n",
        "                          samples_index,\n",
        "                          masks_dir, \n",
        "                          batch_size) {\n",
        "  images_iter <- list.files(images_dir, \n",
        "                            pattern = \".tif\", \n",
        "                            full.names = TRUE)[samples_index] # for current epoch\n",
        "  images_all <- list.files(images_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index]  # for next epoch\n",
        "  masks_iter <- list.files(masks_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index] # for current epoch\n",
        "  masks_all <- list.files(masks_dir, \n",
        "                          pattern = \".tif\",\n",
        "                          full.names = TRUE)[samples_index] # for next epoch\n",
        "  \n",
        "  function() {\n",
        "    \n",
        "    # start new epoch\n",
        "    if (length(images_iter) < batch_size) {\n",
        "      images_iter <<- images_all\n",
        "      masks_iter <<- masks_all\n",
        "    }\n",
        "    \n",
        "    batch_ind <- sample(1:length(images_iter), batch_size)\n",
        "    \n",
        "    batch_images_list <- images_iter[batch_ind]\n",
        "    images_iter <<- images_iter[-batch_ind]\n",
        "    batch_masks_list <- masks_iter[batch_ind]\n",
        "    masks_iter <<- masks_iter[-batch_ind]\n",
        "    \n",
        "    \n",
        "    x_y_batch <- foreach(i = 1:batch_size) %dopar% {\n",
        "      x_y_imgs <- imagesRead(image_file = batch_images_list[i],\n",
        "                             mask_file = batch_masks_list[i])\n",
        "      # without augmentation\n",
        "      ########################################\n",
        "      ########################################\n",
        "      # return as arrays\n",
        "      x_y_arr <- list(x = img2arr(x_y_imgs$img),\n",
        "                      y = mask2arr(x_y_imgs$mask))\n",
        "    }\n",
        "    \n",
        "    x_y_batch <- purrr::transpose(x_y_batch)\n",
        "    \n",
        "    x_batch <- do.call(abind, c(x_y_batch$x, list(along = 1)))\n",
        "    \n",
        "    y_batch <- do.call(abind, c(x_y_batch$y, list(along = 1)))\n",
        "    \n",
        "    result <- list(keras_array(x_batch), keras_array(y_batch))\n",
        "    return(result)\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYfMvUrmZq-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator <- py_iterator(train_generator(images_dir = images_dir,\n",
        "                                              masks_dir = masks_dir,\n",
        "                                              samples_index = train_index,\n",
        "                                              batch_size = batch_size))\n",
        "\n",
        "val_iterator <- py_iterator(val_generator(images_dir = images_dir,\n",
        "                                          masks_dir = masks_dir,\n",
        "                                          samples_index = val_index,\n",
        "                                          batch_size = batch_size))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp6HJ2GQZwZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training -----------------------------------------------------\n",
        "# callbacks\n",
        "callbacks_list <- list(\n",
        "  callback_model_checkpoint(filepath = \"weights_r/unet64_{epoch:03d}.h5\",\n",
        "                            monitor = \"val_custom\",\n",
        "                            save_best_only = FALSE,\n",
        "                            save_weights_only = TRUE,\n",
        "                            mode = \"max\" ,save_freq = TRUE)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_zw3P28afFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model %>% fit_generator(\n",
        "  generator=train_iterator,\n",
        "  steps_per_epoch = as.integer(length(train_index) / batch_size),\n",
        "  epochs = epochs,\n",
        "  validation_data = val_iterator,\n",
        "  validation_steps = as.integer(length(val_index) / batch_size),\n",
        "  verbose = 1,  callbacks = callbacks_list\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}