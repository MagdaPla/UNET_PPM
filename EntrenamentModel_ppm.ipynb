{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EntrenamentModel_ppm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIz64c6+v9vAyfJoNHpxXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MagdaPla/UNET_PPM/blob/master/EntrenamentModel_ppm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHTjL0yDwnsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# codi preparat només per windows\n",
        "# modificat per R-colab, \n",
        "# va a llegir els directoris a GitHub https://github.com/MagdaPla/UNET_PPM.git\n",
        "# per a poder-ho llegir bé, cada vegada monto a sample data la mateixa estructura que al github\n",
        "# canvio nom de Sample_data >>> UNET_PPM\n",
        "# i pujo les dades de nou.\n",
        "\n",
        "# aquest fitxer es va desant per defecte al meu GDrive\n",
        "# cal pujar-ho també al GitHub amb les modificacions\n",
        "\n",
        "\n",
        "# comencem a preparar la informació\n",
        "\n",
        "# 1- eliminem pesos (weights) previs que hi pugui haver\n",
        "unlink(list.files(path = \"UNET_PPM/weights_r/\",full.names = TRUE))\n",
        "\n",
        "# 2- paràmetres d'entrenament\n",
        "\n",
        "epochs = 30 #epochs = 100 \n",
        "batch_size <- 10    #batch_size <- 24\n",
        "DRAW_SAMPLES = TRUE # així copia les dades de validació d'un i altre tipus al directori corresponent\n",
        "no_cores = 6   #no_cores = 12\n",
        "lr_rate = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv3n_kr42jgS",
        "colab_type": "code",
        "outputId": "813f061f-df77-49a8-b969-6e818cbf0185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# instalem els paquets necessaris\n",
        "# a Gcolab ens cal instalarlos ne nou en cada sessió\n",
        "\n",
        "# per instal·lar rgdal al Colab ens cal incloure aquestes dues accions:\n",
        "system(\"sudo apt-get update\")\n",
        "system(\"sudo apt-get install libgdal-dev libproj-dev\")\n",
        "\n",
        "install.packages(\"rgdal\")\n",
        "install.packages(\"keras\")\n",
        "install.packages(\"tensorflow\")\n",
        "install.packages(\"reticulate\")\n",
        "install.packages(\"raster\")\n",
        "install.packages(\"abind\")\n",
        "install.packages(\"foreach\")\n",
        "install.packages(\"parallel\")\n",
        "install.packages(\"doParallel\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Warning message:\n",
            "“package ‘parallel’ is not available (for R version 3.6.3)”\n",
            "Warning message:\n",
            "“package ‘parallel’ is a base package, and should not be updated”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXVJhSJ2coY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "88fda6b7-bb43-4375-f0e5-f681f6ce4390"
      },
      "source": [
        "library(keras)\n",
        "library(tensorflow)\n",
        "library(reticulate)\n",
        "library(raster)\n",
        "library(abind)\n",
        "library(foreach)\n",
        "library(parallel)\n",
        "library(doParallel)\n",
        "library(rgdal)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading required package: sp\n",
            "\n",
            "Loading required package: iterators\n",
            "\n",
            "rgdal: version: 1.4-8, (SVN revision 845)\n",
            " Geospatial Data Abstraction Library extensions to R successfully loaded\n",
            " Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20\n",
            " Path to GDAL shared files: /usr/share/gdal/2.2\n",
            " GDAL binary built with GEOS: TRUE \n",
            " Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]\n",
            " Path to PROJ.4 shared files: (autodetected)\n",
            " Linking to sp version: 1.4-2 \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3MHq4pF7gw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set.seed(104)\n",
        "\n",
        "# per a fer reproduible les probes fixem una llavor\n",
        "# cal tenir present però que el codi que tenim es basa en un exemple basat en tensorflow v1.x\n",
        "# al collab es descarrega una versió 2\n",
        "# feun una adaptació al codi\n",
        "tf<-tf$compat.v1\n",
        "tf$set_random_seed(100)\n",
        "\n",
        "# si no funcionés, canviem el valor \"1\"\n",
        "gpu_options <- tf$GPUOptions(allow_growth=TRUE, per_process_gpu_memory_fraction = 1) #tf$GPUOptions(per_process_gpu_memory_fraction = 0.3)\n",
        "config <- tf$ConfigProto(gpu_options = gpu_options)\n",
        "\n",
        "session_conf <- config\n",
        "sess <- tf$Session(graph = tf$get_default_graph(), config = session_conf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h65SxFmB8Fi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paràmetres -----------------------------------------------------\n",
        "\n",
        "# directoris de les imatges i màscares preparades per l'entrenament/validació\n",
        "images_dir <- \"UNET_PPM/rgb/\" \n",
        "masks_dir <- \"UNET_PPM/masc1/\"\n",
        "\n",
        "# \n",
        "if (DRAW_SAMPLES) {\n",
        "  \n",
        "  unlink(list.files(path = \"UNET_PPM/valid_masc/\",full.names = TRUE))\n",
        "  unlink(list.files(path = \"UNET_PPM/valid_rgb/\",full.names = TRUE))\n",
        "  \n",
        "  # nombre d'imatges per l'entrenament (80%)\n",
        "  train_samples <- length(list.files(images_dir)) #144\n",
        "  train_index <- sample(1:train_samples, round(train_samples * 0.8))\n",
        "  val_index <- c(1:train_samples)[-train_index]\n",
        "  \n",
        "  \n",
        "  # desar les imatges de validació a:\n",
        "  valid_save=list.files(images_dir,full.names = TRUE)\n",
        "  valid_save=valid_save[val_index]\n",
        "  file.copy(from=valid_save,to=\"UNET_PPM/valid_rgb/\")\n",
        "  \n",
        "  valid_save=list.files(masks_dir,full.names = TRUE)\n",
        "  valid_save=valid_save[val_index]\n",
        "  file.copy(from=valid_save,to=\"UNET_PPM/valid_masc/\")\n",
        "  \n",
        "  save(train_index, val_index, file = \"UNET_PPM/train_val_indices.RData\")\n",
        "  \n",
        "} else {\n",
        "  load(\"UNET_PPM/train_val_indices.RData\", verbose=T)\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcPoh92I8qTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funció \"Loss\"  -----------------------------------------------------\n",
        "\n",
        "# hem d'adaptar la manera de fer el set_session de keras v2 a v1\n",
        "K<-tf$compat.v1.keras.backend\n",
        "K$set_session(sess)\n",
        "\n",
        "dice_coef <- custom_metric(\"custom\", function(y_true, y_pred, smooth = 1.0) {\n",
        "  y_true_f <- k_flatten(y_true)\n",
        "  y_pred_f <- k_flatten(y_pred)\n",
        "  intersection <- k_sum(y_true_f * y_pred_f)\n",
        "  result <- (2 * intersection + smooth) / \n",
        "    (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n",
        "  return(result)\n",
        "})\n",
        "\n",
        "bce_dice_loss <- function(y_true, y_pred) {\n",
        "  result <- loss_binary_crossentropy(y_true, y_pred) +\n",
        "    (1 - dice_coef(y_true, y_pred))\n",
        "  return(result)\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcN6dhhdADb5",
        "colab_type": "code",
        "outputId": "eeda8676-37d4-4a75-b41e-e773c9448d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# afegim \"sequential()\" abans de córrer al model (no inclos en el codi original)\n",
        "model <- keras_model_sequential()\n",
        "\n",
        "# U-net 128 -----------------------------------------------------\n",
        "\n",
        "get_unet_128 <- function(input_shape = c(128, 128, 3),\n",
        "                         num_classes = 1) {\n",
        "  \n",
        "  inputs <- layer_input(shape = input_shape)\n",
        "  # 128\n",
        "  \n",
        "  down1 <- inputs %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down1_pool <- down1 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 64\n",
        "  \n",
        "  down2 <- down1_pool %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down2_pool <- down2 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 32\n",
        "  \n",
        "  down3 <- down2_pool %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down3_pool <- down3 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 16\n",
        "  \n",
        "  down4 <- down3_pool %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  down4_pool <- down4 %>%\n",
        "    layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))\n",
        "  # 8\n",
        "  \n",
        "  center <- down4_pool %>%\n",
        "    layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") \n",
        "  # center\n",
        "  \n",
        "  up4 <- center %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down4, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 16\n",
        "  \n",
        "  up3 <- up4 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down3, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 32\n",
        "  \n",
        "  up2 <- up3 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down2, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 64\n",
        "  \n",
        "  up1 <- up2 %>%\n",
        "    layer_upsampling_2d(size = c(2, 2)) %>%\n",
        "    {layer_concatenate(inputs = list(down1, .), axis = 3)} %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\") %>%\n",
        "    layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_activation(\"relu\")\n",
        "  # 128\n",
        "  \n",
        "  classify <- layer_conv_2d(up1,\n",
        "                            filters = num_classes, \n",
        "                            kernel_size = c(1, 1),\n",
        "                            activation = \"softmax\") #sigmoid\n",
        "  \n",
        "  \n",
        "  model <- keras_model(\n",
        "    inputs = inputs,\n",
        "    outputs = classify\n",
        "  )\n",
        "  \n",
        "  model %>% compile(\n",
        "    optimizer = optimizer_adam(), #optimizer_rmsprop(lr = 0.0001)\n",
        "    loss = bce_dice_loss,\n",
        "    metrics =  c(dice_coef) \n",
        "  )\n",
        "  \n",
        "  return(model)\n",
        "}\n",
        "\n",
        "model <- get_unet_128()\n",
        "model\n",
        "\n",
        "# per utilitzar \"pesos\" d'entrenaments previes utilitzar la funció: \"load_model_weights_hdf5\"\n",
        "# per exemple:\n",
        "# load_model_weights_hdf5(model, \"./weights_r_save/unet64_178.h5\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model\n",
              "Model: \"model_5\"\n",
              "________________________________________________________________________________\n",
              "Layer (type)              Output Shape      Param #  Connected to               \n",
              "================================================================================\n",
              "input_6 (InputLayer)      [(None, 128, 128, 0                                   \n",
              "________________________________________________________________________________\n",
              "conv2d_115 (Conv2D)       (None, 128, 128,  1792     input_6[0][0]              \n",
              "________________________________________________________________________________\n",
              "batch_normalization_110 ( (None, 128, 128,  256      conv2d_115[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_110 (Activatio (None, 128, 128,  0        batch_normalization_110[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_116 (Conv2D)       (None, 128, 128,  36928    activation_110[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_111 ( (None, 128, 128,  256      conv2d_116[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_111 (Activatio (None, 128, 128,  0        batch_normalization_111[0][\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_20 (MaxPool (None, 64, 64, 64 0        activation_111[0][0]       \n",
              "________________________________________________________________________________\n",
              "conv2d_117 (Conv2D)       (None, 64, 64, 12 73856    max_pooling2d_20[0][0]     \n",
              "________________________________________________________________________________\n",
              "batch_normalization_112 ( (None, 64, 64, 12 512      conv2d_117[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_112 (Activatio (None, 64, 64, 12 0        batch_normalization_112[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_118 (Conv2D)       (None, 64, 64, 12 147584   activation_112[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_113 ( (None, 64, 64, 12 512      conv2d_118[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_113 (Activatio (None, 64, 64, 12 0        batch_normalization_113[0][\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_21 (MaxPool (None, 32, 32, 12 0        activation_113[0][0]       \n",
              "________________________________________________________________________________\n",
              "conv2d_119 (Conv2D)       (None, 32, 32, 25 295168   max_pooling2d_21[0][0]     \n",
              "________________________________________________________________________________\n",
              "batch_normalization_114 ( (None, 32, 32, 25 1024     conv2d_119[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_114 (Activatio (None, 32, 32, 25 0        batch_normalization_114[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_120 (Conv2D)       (None, 32, 32, 25 590080   activation_114[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_115 ( (None, 32, 32, 25 1024     conv2d_120[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_115 (Activatio (None, 32, 32, 25 0        batch_normalization_115[0][\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_22 (MaxPool (None, 16, 16, 25 0        activation_115[0][0]       \n",
              "________________________________________________________________________________\n",
              "conv2d_121 (Conv2D)       (None, 16, 16, 51 1180160  max_pooling2d_22[0][0]     \n",
              "________________________________________________________________________________\n",
              "batch_normalization_116 ( (None, 16, 16, 51 2048     conv2d_121[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_116 (Activatio (None, 16, 16, 51 0        batch_normalization_116[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_122 (Conv2D)       (None, 16, 16, 51 2359808  activation_116[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_117 ( (None, 16, 16, 51 2048     conv2d_122[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_117 (Activatio (None, 16, 16, 51 0        batch_normalization_117[0][\n",
              "________________________________________________________________________________\n",
              "max_pooling2d_23 (MaxPool (None, 8, 8, 512) 0        activation_117[0][0]       \n",
              "________________________________________________________________________________\n",
              "conv2d_123 (Conv2D)       (None, 8, 8, 1024 4719616  max_pooling2d_23[0][0]     \n",
              "________________________________________________________________________________\n",
              "batch_normalization_118 ( (None, 8, 8, 1024 4096     conv2d_123[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_118 (Activatio (None, 8, 8, 1024 0        batch_normalization_118[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_124 (Conv2D)       (None, 8, 8, 1024 9438208  activation_118[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_119 ( (None, 8, 8, 1024 4096     conv2d_124[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_119 (Activatio (None, 8, 8, 1024 0        batch_normalization_119[0][\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_20 (UpSampl (None, 16, 16, 10 0        activation_119[0][0]       \n",
              "________________________________________________________________________________\n",
              "concatenate_20 (Concatena (None, 16, 16, 15 0        activation_117[0][0]       \n",
              "                                                     up_sampling2d_20[0][0]     \n",
              "________________________________________________________________________________\n",
              "conv2d_125 (Conv2D)       (None, 16, 16, 51 7078400  concatenate_20[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_120 ( (None, 16, 16, 51 2048     conv2d_125[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_120 (Activatio (None, 16, 16, 51 0        batch_normalization_120[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_126 (Conv2D)       (None, 16, 16, 51 2359808  activation_120[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_121 ( (None, 16, 16, 51 2048     conv2d_126[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_121 (Activatio (None, 16, 16, 51 0        batch_normalization_121[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_127 (Conv2D)       (None, 16, 16, 51 2359808  activation_121[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_122 ( (None, 16, 16, 51 2048     conv2d_127[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_122 (Activatio (None, 16, 16, 51 0        batch_normalization_122[0][\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_21 (UpSampl (None, 32, 32, 51 0        activation_122[0][0]       \n",
              "________________________________________________________________________________\n",
              "concatenate_21 (Concatena (None, 32, 32, 76 0        activation_115[0][0]       \n",
              "                                                     up_sampling2d_21[0][0]     \n",
              "________________________________________________________________________________\n",
              "conv2d_128 (Conv2D)       (None, 32, 32, 25 1769728  concatenate_21[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_123 ( (None, 32, 32, 25 1024     conv2d_128[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_123 (Activatio (None, 32, 32, 25 0        batch_normalization_123[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_129 (Conv2D)       (None, 32, 32, 25 590080   activation_123[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_124 ( (None, 32, 32, 25 1024     conv2d_129[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_124 (Activatio (None, 32, 32, 25 0        batch_normalization_124[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_130 (Conv2D)       (None, 32, 32, 25 590080   activation_124[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_125 ( (None, 32, 32, 25 1024     conv2d_130[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_125 (Activatio (None, 32, 32, 25 0        batch_normalization_125[0][\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_22 (UpSampl (None, 64, 64, 25 0        activation_125[0][0]       \n",
              "________________________________________________________________________________\n",
              "concatenate_22 (Concatena (None, 64, 64, 38 0        activation_113[0][0]       \n",
              "                                                     up_sampling2d_22[0][0]     \n",
              "________________________________________________________________________________\n",
              "conv2d_131 (Conv2D)       (None, 64, 64, 12 442496   concatenate_22[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_126 ( (None, 64, 64, 12 512      conv2d_131[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_126 (Activatio (None, 64, 64, 12 0        batch_normalization_126[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_132 (Conv2D)       (None, 64, 64, 12 147584   activation_126[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_127 ( (None, 64, 64, 12 512      conv2d_132[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_127 (Activatio (None, 64, 64, 12 0        batch_normalization_127[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_133 (Conv2D)       (None, 64, 64, 12 147584   activation_127[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_128 ( (None, 64, 64, 12 512      conv2d_133[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_128 (Activatio (None, 64, 64, 12 0        batch_normalization_128[0][\n",
              "________________________________________________________________________________\n",
              "up_sampling2d_23 (UpSampl (None, 128, 128,  0        activation_128[0][0]       \n",
              "________________________________________________________________________________\n",
              "concatenate_23 (Concatena (None, 128, 128,  0        activation_111[0][0]       \n",
              "                                                     up_sampling2d_23[0][0]     \n",
              "________________________________________________________________________________\n",
              "conv2d_134 (Conv2D)       (None, 128, 128,  110656   concatenate_23[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_129 ( (None, 128, 128,  256      conv2d_134[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_129 (Activatio (None, 128, 128,  0        batch_normalization_129[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_135 (Conv2D)       (None, 128, 128,  36928    activation_129[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_130 ( (None, 128, 128,  256      conv2d_135[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_130 (Activatio (None, 128, 128,  0        batch_normalization_130[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_136 (Conv2D)       (None, 128, 128,  36928    activation_130[0][0]       \n",
              "________________________________________________________________________________\n",
              "batch_normalization_131 ( (None, 128, 128,  256      conv2d_136[0][0]           \n",
              "________________________________________________________________________________\n",
              "activation_131 (Activatio (None, 128, 128,  0        batch_normalization_131[0][\n",
              "________________________________________________________________________________\n",
              "conv2d_137 (Conv2D)       (None, 128, 128,  65       activation_131[0][0]       \n",
              "================================================================================\n",
              "Total params: 34,540,737\n",
              "Trainable params: 34,527,041\n",
              "Non-trainable params: 13,696\n",
              "________________________________________________________________________________\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzOkOrzKAbZO",
        "colab_type": "code",
        "outputId": "1477811a-3826-4ad0-dc89-bed5c738119b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "## definim el nombre de clusters\n",
        "cl <- makePSOCKcluster(no_cores) \n",
        "\n",
        "clusterEvalQ(cl, {\n",
        "  \n",
        "  library(abind)     \n",
        "  library(raster)\n",
        "  library(reticulate)\n",
        "  \n",
        "  # Llegim funcions d'augment -----------------------------------------------------\n",
        "  \n",
        "  imagesRead <- function(image_file,mask_file)\n",
        "  {\n",
        "    \n",
        "    img <- brick(image_file)\n",
        "    mask <- raster(mask_file)\n",
        "    \n",
        "    return(list(img = img, mask = mask))\n",
        "  }\n",
        "  \n",
        "  # randomHorizontalFlip : rotacions i inversions + rotacions\n",
        "  randomHorizontalFlip <- function(img,mask,u = 0) {\n",
        "    if (rnorm(1) < u) return(list(img = img, mask = mask))\n",
        "    r_angle=sample(c(2,3,4,5,6,7,8),1)\n",
        "    if(r_angle==2) {return(list(img = flip(t(img),direction = 1), mask = flip(t(mask),direction = 1)))}\n",
        "    if(r_angle==3) {return(list(img = flip(t(flip(t(img),direction = 1)),direction = 1), mask = flip(t(flip(t(mask),direction = 1)),direction = 1)))}\n",
        "    if(r_angle==4) {return(list(img = flip(t(img),direction = 2), mask = flip(t(mask),direction = 2)))}\n",
        "    if(r_angle==5) {return(list(img = flip(img,direction = 1), mask = flip(mask,direction = 1)))}\n",
        "    if(r_angle==6) {return(list(img = flip(t(flip(img,direction = 1)),direction = 1), mask = flip(t(flip(mask,direction = 1)),direction = 1)))}\n",
        "    if(r_angle==7) {return(list(img = flip(t(flip(t(flip(img,direction = 1)),direction = 1)),direction = 1), mask = flip(t(flip(t(flip(mask,direction = 1)),direction = 1)),direction = 1)))}\n",
        "    if(r_angle==8) {return(list(img = flip(t(flip(img,direction = 1)),direction = 2), mask = flip(t(flip(mask,direction = 1)),direction = 2)))}\n",
        "  }\n",
        "  \n",
        "  # add a shift to the bands\n",
        "  randomVariability = function(img, u = 0, variability = c(90, 110)) {\n",
        "    if (rnorm(1) < u) return(img)\n",
        "    variability_shift = runif(1, variability[1], variability[2])/100\n",
        "    img = img * variability_shift\n",
        "    return(img)\n",
        "  }\n",
        "  \n",
        "  \n",
        "  img2arr <- function(image) {\n",
        "    image <- as.array(image)\n",
        "    result <- aperm(image, c(2,1,3))\n",
        "    result <- result/255 # to have values between 0 and 1\n",
        "    array_reshape(result,  c(1, dim(image)[1], dim(image)[2], dim(image)[3]))\n",
        "  }\n",
        "  \n",
        "  \n",
        "  mask2arr <- function(mask) {\n",
        "    mask=as.array(mask[[1]])\n",
        "    result <- aperm(mask, c(2,1,3))\n",
        "    result=result[,,1]\n",
        "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
        "  }\n",
        "  \n",
        "})\n",
        "\n",
        "\n",
        "registerDoParallel(cl)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[[1]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[2]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[3]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[4]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[5]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n",
              "\n",
              "[[6]]\n",
              "function(mask) {\n",
              "    mask=as.array(mask[[1]])\n",
              "    result <- aperm(mask, c(2,1,3))\n",
              "    result=result[,,1]\n",
              "    array_reshape(result,  c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n",
              "  }\n"
            ],
            "text/latex": "\\begin{enumerate}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\item \\begin{minted}{r}\nfunction (mask) \n\\{\n    mask = as.array(mask{[}{[}1{]}{]})\n    result <- aperm(mask, c(2, 1, 3))\n    result = result{[}, , 1{]}\n    array\\_reshape(result, c(1, dim(mask){[}1{]}, dim(mask){[}2{]}, dim(mask){[}3{]}))\n\\}\n\\end{minted}\n\\end{enumerate}\n",
            "text/markdown": "1. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n2. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n3. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n4. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n5. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n6. ```r\nfunction (mask) \n{\n    mask = as.array(mask[[1]])\n    result <- aperm(mask, c(2, 1, 3))\n    result = result[, , 1]\n    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))\n}\n```\n\n\n",
            "text/html": [
              "<ol>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "\t<li><pre class=language-r><code>function (mask) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    mask = as.array(mask[[1]])</span>\n",
              "<span style=white-space:pre-wrap>    result &lt;- aperm(mask, c(2, 1, 3))</span>\n",
              "<span style=white-space:pre-wrap>    result = result[, , 1]</span>\n",
              "<span style=white-space:pre-wrap>    array_reshape(result, c(1, dim(mask)[1], dim(mask)[2], dim(mask)[3]))</span>\n",
              "}</code></pre></li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ZGInTRBH46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator <- function(images_dir, \n",
        "                            samples_index,\n",
        "                            masks_dir, \n",
        "                            batch_size) {\n",
        "  images_iter <- list.files(images_dir, \n",
        "                            pattern = \".tif\", \n",
        "                            full.names = TRUE)[samples_index] # for current epoch\n",
        "  images_all <- list.files(images_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index]  # for next epoch\n",
        "  masks_iter <- list.files(masks_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index] # for current epoch\n",
        "  masks_all <- list.files(masks_dir, \n",
        "                          pattern = \".tif\",\n",
        "                          full.names = TRUE)[samples_index] # for next epoch\n",
        "  \n",
        "  function() {\n",
        "      \n",
        "    # start new epoch\n",
        "    if (length(images_iter) < batch_size) {\n",
        "      images_iter <<- images_all\n",
        "      masks_iter <<- masks_all\n",
        "    }\n",
        "    \n",
        "    batch_ind <- sample(1:length(images_iter), batch_size)\n",
        "    \n",
        "    batch_images_list <- images_iter[batch_ind]\n",
        "    images_iter <<- images_iter[-batch_ind]\n",
        "    batch_masks_list <- masks_iter[batch_ind]\n",
        "    masks_iter <<- masks_iter[-batch_ind]\n",
        "    \n",
        "    \n",
        "    x_y_batch <- foreach(i = 1:batch_size) %dopar% {\n",
        "      x_y_imgs <- imagesRead(image_file = batch_images_list[i],\n",
        "                             mask_file = batch_masks_list[i])\n",
        "      \n",
        "      # flip all side and invert\n",
        "      x_y_imgs <- randomHorizontalFlip(x_y_imgs$img,x_y_imgs$mask)\n",
        "      \n",
        "      # add some variability to the values\n",
        "      x_y_imgs$img = randomVariability(x_y_imgs$img, u = 0, variability = c(90, 110))\n",
        "      \n",
        "      # return as arrays\n",
        "      x_y_arr <- list(x = img2arr(x_y_imgs$img),\n",
        "                      y = mask2arr(x_y_imgs$mask))\n",
        "    }\n",
        "    \n",
        "    x_y_batch <- purrr::transpose(x_y_batch)\n",
        "    \n",
        "    x_batch <- do.call(abind, c(x_y_batch$x, list(along = 1)))\n",
        "    \n",
        "    y_batch <- do.call(abind, c(x_y_batch$y, list(along = 1)))\n",
        "    \n",
        "    result <- list(keras_array(x_batch), keras_array(y_batch))\n",
        "    return(result)\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWgIVMo3BRlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_generator <- function(images_dir, \n",
        "                          samples_index,\n",
        "                          masks_dir, \n",
        "                          batch_size) {\n",
        "  images_iter <- list.files(images_dir, \n",
        "                            pattern = \".tif\", \n",
        "                            full.names = TRUE)[samples_index] # for current epoch\n",
        "  images_all <- list.files(images_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index]  # for next epoch\n",
        "  masks_iter <- list.files(masks_dir, \n",
        "                           pattern = \".tif\",\n",
        "                           full.names = TRUE)[samples_index] # for current epoch\n",
        "  masks_all <- list.files(masks_dir, \n",
        "                          pattern = \".tif\",\n",
        "                          full.names = TRUE)[samples_index] # for next epoch\n",
        "  \n",
        "  function() {\n",
        "    \n",
        "    # start new epoch\n",
        "    if (length(images_iter) < batch_size) {\n",
        "      images_iter <<- images_all\n",
        "      masks_iter <<- masks_all\n",
        "    }\n",
        "    \n",
        "    batch_ind <- sample(1:length(images_iter), batch_size)\n",
        "    \n",
        "    batch_images_list <- images_iter[batch_ind]\n",
        "    images_iter <<- images_iter[-batch_ind]\n",
        "    batch_masks_list <- masks_iter[batch_ind]\n",
        "    masks_iter <<- masks_iter[-batch_ind]\n",
        "    \n",
        "    \n",
        "    x_y_batch <- foreach(i = 1:batch_size) %dopar% {\n",
        "      x_y_imgs <- imagesRead(image_file = batch_images_list[i],\n",
        "                             mask_file = batch_masks_list[i])\n",
        "      # without augmentation\n",
        "      ########################################\n",
        "      ########################################\n",
        "      # return as arrays\n",
        "      x_y_arr <- list(x = img2arr(x_y_imgs$img),\n",
        "                      y = mask2arr(x_y_imgs$mask))\n",
        "    }\n",
        "    \n",
        "    x_y_batch <- purrr::transpose(x_y_batch)\n",
        "    \n",
        "    x_batch <- do.call(abind, c(x_y_batch$x, list(along = 1)))\n",
        "    \n",
        "    y_batch <- do.call(abind, c(x_y_batch$y, list(along = 1)))\n",
        "    \n",
        "    result <- list(keras_array(x_batch), keras_array(y_batch))\n",
        "    return(result)\n",
        "  }\n",
        "}\n",
        "\n",
        "train_iterator <- py_iterator(train_generator(images_dir = images_dir,\n",
        "                                              masks_dir = masks_dir,\n",
        "                                              samples_index = train_index,\n",
        "                                              batch_size = batch_size))\n",
        "\n",
        "val_iterator <- py_iterator(val_generator(images_dir = images_dir,\n",
        "                                          masks_dir = masks_dir,\n",
        "                                          samples_index = val_index,\n",
        "                                          batch_size = batch_size))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm6ShPVWBbcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entrenament -----------------------------------------------------\n",
        "\n",
        "# callbacks\n",
        "callbacks_list <- list(\n",
        "  callback_model_checkpoint(filepath = \"UNET_PPM/weights_r/unet64_{epoch:03d}.h5\",\n",
        "                            monitor = \"val_custom\",\n",
        "                            save_best_only = FALSE,\n",
        "                            save_weights_only = TRUE,\n",
        "                            mode = \"max\" ,save_freq = TRUE)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9pYk1onBuGY",
        "colab_type": "code",
        "outputId": "13c4a63e-9ce4-4bb5-8889-5f0f3f73d4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model %>% fit_generator(\n",
        "  generator=train_iterator,\n",
        "  steps_per_epoch = as.integer(length(train_index) / batch_size),\n",
        "  epochs = epochs,\n",
        "  validation_data = val_iterator,\n",
        "  validation_steps = as.integer(length(val_index) / batch_size),\n",
        "  verbose = 1,  callbacks = callbacks_list\n",
        ")\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in py_call_impl(callable, dots$args, dots$keywords): ValueError: in user code:\n\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:541 train_step  **\n        self.trainable_variables)\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1804 _minimize\n        trainable_variables))\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    //usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['conv2d_115/kernel:0', 'conv2d_115/bias:0', 'batch_normalization_110/gamma:0', 'batch_normalization_110/beta:0', 'conv2d_116/kernel:0', 'conv2d_116/bias:0', 'batch_normalization_111/gamma:0', 'batch_normalization_111/beta:0', 'conv2d_117/kernel:0', 'conv2d_117/bias:0', 'batch_normalization_112/gamma:0', 'batch_normalization_112/beta:0', 'conv2d_118/kernel:0', 'conv2d_118/bias:0', 'batch_normalization_113/gamma:0', 'batch_normalization_113/beta:0', 'conv2d_119/kernel:0', 'conv2d_119/bias:0', 'batch_normalization_114/gamma:0', 'batch_normalization_114/beta:0', 'conv2d_120/kernel:0', 'conv2d_120/bias:0', 'batch_normalization_115/gamma:0', 'batch_normalization_115/beta:0', 'conv2d_121/kernel:0', 'conv2d_121/bias:0', 'batch_normalization_116/gamma:0', 'batch_normalization_116/beta:0', 'conv2d_122/kernel:0', 'conv2d_122/bias:0', 'batch_normalization_117/gamma:0', 'batch_normalization_117/beta:0', 'conv2d_123/kernel:0', 'conv2d_123/bias:0', 'batch_normalization_118/gamma:0', 'batch_normalization_118/beta:0', 'conv2d_124/kernel:0', 'conv2d_124/bias:0', 'batch_normalization_119/gamma:0', 'batch_normalization_119/beta:0', 'conv2d_125/kernel:0', 'conv2d_125/bias:0', 'batch_normalization_120/gamma:0', 'batch_normalization_120/beta:0', 'conv2d_126/kernel:0', 'conv2d_126/bias:0', 'batch_normalization_121/gamma:0', 'batch_normalization_121/beta:0', 'conv2d_127/kernel:0', 'conv2d_127/bias:0', 'batch_normalization_122/gamma:0', 'batc...\n\n\nDetailed traceback: \n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1479, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\n    return method(self, *args, **kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\n    tmp_logs = train_function(iterator)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n    result = self._call(*args, **kwds)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\n    self._initialize(args, kwds, add_initializers_to=initializers)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\n    *args, **kwds))\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File \"//usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 968, in wrapper\n    raise e.ag_error_metadata.to_exception(e)\n\nTraceback:\n",
            "1. model %>% fit_generator(generator = train_iterator, steps_per_epoch = as.integer(length(train_index)/batch_size), \n .     epochs = epochs, validation_data = val_iterator, validation_steps = as.integer(length(val_index)/batch_size), \n .     verbose = 1, callbacks = callbacks_list)",
            "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
            "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
            "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
            "5. `_fseq`(`_lhs`)",
            "6. freduce(value, `_function_list`)",
            "7. withVisible(function_list[[k]](value))",
            "8. function_list[[k]](value)",
            "9. fit_generator(., generator = train_iterator, steps_per_epoch = as.integer(length(train_index)/batch_size), \n .     epochs = epochs, validation_data = val_iterator, validation_steps = as.integer(length(val_index)/batch_size), \n .     verbose = 1, callbacks = callbacks_list)",
            "10. call_generator_function(object$fit_generator, list(generator = generator, \n  .     steps_per_epoch = as.integer(steps_per_epoch), epochs = as.integer(epochs), \n  .     verbose = as.integer(verbose), callbacks = normalize_callbacks_with_metrics(view_metrics, \n  .         callbacks), validation_data = validation_data, validation_steps = as_nullable_integer(validation_steps), \n  .     class_weight = as_class_weight(class_weight), max_queue_size = as.integer(max_queue_size), \n  .     workers = as.integer(workers), initial_epoch = as.integer(initial_epoch)))",
            "11. do.call(func, args)",
            "12. (structure(function (...) \n  . {\n  .     dots <- py_resolve_dots(list(...))\n  .     result <- py_call_impl(callable, dots$args, dots$keywords)\n  .     if (convert) \n  .         result <- py_to_r(result)\n  .     if (is.null(result)) \n  .         invisible(result)\n  .     else result\n  . }, class = c(\"python.builtin.method\", \"python.builtin.object\"\n  . ), py_object = <environment>))(generator = <environment>, steps_per_epoch = 11L, \n  .     epochs = 30L, verbose = 1L, callbacks = list(<environment>, \n  .         <environment>), validation_data = <environment>, validation_steps = 2L, \n  .     class_weight = NULL, max_queue_size = 10L, workers = 1L, \n  .     initial_epoch = 0L, use_multiprocessing = FALSE)",
            "13. py_call_impl(callable, dots$args, dots$keywords)"
          ]
        }
      ]
    }
  ]
}